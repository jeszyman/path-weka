* Best Anemia Predictor Competition
** Introduction

In this exercise, you will use the principles of data pre-processing, data mining, and machine learning to solve a supervised machine learning classifier problem. The classifier will predict future anemia based on a patient's current CBC. This is a competition, and the best performing classifiers will win prizes!

** Setup

- If you have not already done so, download and install the Weka program: 

https://www.cs.waikato.ac.nz/ml/weka/downloading.html

- Get the stable version for your operating system including the Java VM. 

For example, if you are on Windows, then get the "self-extracting executable for 64-bit Windows that includes Oracle's 64-bit Java VM 1.8":


[[file:./tutorial-images/windows-dl-ex.png]]

- Follow the install instructions in the downloaded file.

- You do not need to install any additional packages, just the base Weka program is enough for this exercise.  

** Data

We will use the CBC data from last week's data mining and pre-processing lecture. _The .csv and .arff files were emailed to you (machine-cbc.csv, machine-cbc.arff)_. All of these CBC results have normal hemoglobin and hematocrit, but half of the patients will be anemic on their /next/ CBC. The subsAnemia column in the .csv file identifies which patients will be anemic on their next CBC.

Recall, this was several days of CBC with differential results from Cerner Millennium that went through the following pre-preprocessing steps: 

1. Long-to-wide format change for DTAs
2. Subset to CBCs where patient was not currently anemic
3. Subset to a case-control series with comparable distributions of hemoglobin and hematocrit: 
  - Cases: Patient's next CBC was anemic
  - Control: Patient's next CBC was not anemic 
4. Removed patient identifiers


[[file:./tutorial-images/design.png]]

** Pre-processing and Data Mining

The data in machine-cbc.csv could to be substantially more pre-processed before loading it into Weka. For example, AGE is listed as "## Years" (e.g. "45 Years" instead of just 45). Weka is going to interpret the AGE column as a nominal variable instead of a continuous variable. The "match" and "m" columns were created as part of the case-control partition. They have a 1:1 correlation with the subsAnemia column and, therefore, contain no information. Some machine learning algorithms are affected by these correlated variables. For example, they can mask interactions that would otherwise be discovered by a random forest classifier. Finally, there are useful features within our data which would improve our classifier, but which have not been calculated yet. For example, the difference between the test order time and specimen received time can vary dramatically. Perhaps nurses wait longer to draw blood from stable patients, and the order-to-receive interval correlates with less subsequent anemia because these patients are more stable. We can calculate the order-to-receive interval and use this as another variable in our machine learning.

The pre-processing tasks for machine learning are generally the same as for other analysis, but with special emphasis on cleaning, formatting, and transformation. 
- Removing the "m" and "match" variables is an example of cleaning. 
- Changing AGE to just a number is an example of formatting. 
- Calculating the order-to-receive interval is an example of transformation. (Specifically, this is feature engineering. Other types of transformation include scaling and aggregation.) 

In email, I have provided you our minimally processed CBC data both as a comma-separated value file (.csv) and as a weka-specific format (.arff). The .arff is ready to use directly in Weka, but *you will not get the best classifier without some more pre-processing of the .csv.*

*Data that has not been carefully pre-processed will produce meaningless results,* even if the machine learning algorithm runs successfully. This is the GIGO principle- [[https://en.wikipedia.org/wiki/Garbage_in,_garbage_out][garbage in, garbage out]]. 

** _OBJECTIVE: Your job is to use the available CBC data to predict which patients will become anemic._
In machine learning, this is an example of a supervised learning classifier problem. We will present the computer with examples of our two outcomes (subsequently anemic versus subsequently not anemic) and ask the computer to learn rules or patterns in the data that correlate with each group.  

Note: These results were selected so that the subs-anemia groups have comparable distributions of hemoglobin and hematocrit (see distributions above, for method see [[file:./cbc-preprocess.R]]).

** Supervised Machine Learning Classifier
*** Import Data

Weka uses a specialized file format, .arff, which is just a .csv file with some extra header material. Weka can convert .csv files to .arff in the ARFF Viewer tool. 

- Open Weka, you will see the Wek GUI Chooser window
- Under the Tools menu at the top, choose ArffViewer: 

[[./tutorial-images/weka-open.png]]


- In the ARFF Viewer, open the .csv your would like to import:

[[file:./tutorial-images/arff-viewer.png]]

- And a window showing this data will appear: 

[[file:./tutorial-images/arff-data.png]]

- *CRITICAL:* Before proceeding, you must tell Weka which variable it should use to classify data. For our data, that is the subsAnemia column. Right-click that column header and select "Set Attribute as Class": 

[[file:./tutorial-images/att-as-class.png]]

- The subsAnemia column header should now be bold and the column should move to the far right of the table: 

[[file:./tutorial-images/subsAnemia-att.png]]

- Now you can save the data as an .arff file. Just click File -> Save as, and add an arff extension: 

[[file:./tutorial-images/save-arff.png]]

*** Introduction to Classifier Algorithms

- Now we're ready to try some machine learning! Go back to the Weka GUI Chooser and select the Explorer button: 

[[file:./tutorial-images/open-arff.png]]

- Open the .arff file you just made, then go to the Classify tab:

[[file:./tutorial-images/classify-tab.png]]

- Without adjusting any settings, just hit "Start". 

- The default algorithm is ZeroR. Weka will run the ZeroR algorithm and output will appear in the Classifier output window:   

[[file:./tutorial-images/classify-output.png]]

- Scroll down to === Summary === where you will see about 1/2 of cases were classified correctly. That's because ZeroR is just picking the most common category (or in our case the first category) and assigning every instance to that category. So instances with subsAnemia = normal get classified as normal and those with subsAnemia = anemic ... also get classified as normal! We run the ZeroR algorithm as a baseline- any other algorithm should perform better than this. 

- The "Choose" button in the classifier window allows you to select different machine learning algorithms. 

[[file:./tutorial-images/classify-type.

We'll go over a couple in class, but the specifics of each algorithm, it's assumptions, settings, and output, are beyond the scope of this exercise. See the Resources and References section to learn more. 

***  and Cross Validation

*** Begin Classifying the Dataset


** Competition 

Iterate through the above process as much as you like to improve your classification. 

- [ ] Include resources


You objective is to improve this classifier to get the highest possible correct classification using 10-fold cross validation. You will need to draw on strategies from the machine learning and data pre-processing lectures. These strategies include: 

- Optimize your dataset
  - Unless you direct Weka otherwise, it will use all the variables and all of the CBC values in your dataset, as is, for classification. You may improve your classification by changing the input data- using less variables, normalizing variables, re-scaling variables, or excluding incomplete values. 
- Select a better classification algorithm
  - The Choose button under the Classifier heading will direct you to a wide selection of classifier methods. 
  - [ ] Some common methods for this type of exercise include...
- Optimize your classifier algorithm
  - Each classifier algorithm has a set of pre-selected input parameters which are probably not optimized for this dataset. Select the text window to the right of the Choose button to change these parameters, then re-run to see if your classification gets better. 
  - [ ] These are explained in LINK

Keep in mind that each model is a unique problem, and there is no single "best" machine learning algorithm to classify instances in the model. This is a 
representation of the [[https://en.wikipedia.org/wiki/No_free_lunch_theorem][no free lunch theorem]]    
** Resources and References
- Weka Documentation
  - [[https://waikato.github.io/weka-wiki/search.html?q=time][wiki]]


** DEL 
IMAGES
- study design
- ML process

OTHER ideas- normochromic only- WHO def, what about normocytic? 
