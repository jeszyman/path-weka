IMAGES
- study design
- ML process

OTHER ideas- normochromic only- WHO def, what about normocytic? 

* Best Anemia Predictor Competition
** Introduction

In this exercise, you will use the principles of data pre-processing, data mining, and machine learning to solve a supervised machine learning classifier problem. The classifier will predict future anemia based on a patient's current CBC. This is a competition, and the best performing classifiers will win prizes!

** Setup

If you have not already done so, download and install the Weka program: 

https://www.cs.waikato.ac.nz/ml/weka/downloading.html

Get the stable version for your operating system including the Java VM. 

For example, if you are on Windows, then get the "self-extracting executable for 64-bit Windows that includes Oracle's 64-bit Java VM 1.8":


[[file:./tutorial-images/windows-dl-ex.png]]

Follow the install instructions in the downloaded file.

You do not need to install any additional packages, just the base Weka program is enough for this exercise.  

** Data

We will use the CBC data from last week's data mining and pre-processing lecture. _The .csv and .arff files were emailed to you (machine-cbc.csv, machine-cbc.arff)_. All of these CBC results have normal hemoglobin and hematocrit, but half of the patients will be anemic on their next CBC. The subsAnemia column in the .csv file identifies which patients will be anemic on their next CBC.

Recall, this was several days of CBC with differential results from Cerner Millennium that went through the following pre-preprocessing steps: 

1. Long-to-wide format change for DTAs
2. Subset to CBCs where patient was not currently anemic
3. Subset to a case-control series with comparable distributions of hemoglobin and hematocrit: 
  - Cases: Patient's next CBC was anemic
  - Control: Patient's next CBC was not anemic 
4. Removed patient identifiers


[[file:./tutorial-images/design.png]]


** Pre-processing and Data Mining

The data in machine-cbc.csv could to be substantially more pre-processed before loading it into Weka. For example, AGE is listed as "## Years" (e.g. "45 Years" instead of just 45). Weka is going to interpret the AGE column as a nominal variable instead of a continuous variable. The "match" and "m" columns were created as part of the case-control partition. They have a 1:1 correlation with the subsAnemia column and, therefore, contain no information. Some machine learning algorithms are affected by these correlated variables. For example, they can mask interactions that would otherwise be discovered by a random forest classifier. Finally, there are useful features within our data which would improve our classifier, but which have not been calculated yet. For example, the difference between the test order time and specimen received time can vary dramatically. Perhaps nurses wait longer to draw blood from stable patients, and the order-to-receive interval correlates with less subsequent anemia. We can calculate the order-to-receive interval and use this as another variable in our machine learning.

The pre-processing tasks for machine learning are generally the same as for other analysis, but with special emphasis on cleaning, formatting, and transformation. 
- Removing the "m" and "match" variables is an example of cleaning. 
- Changing AGE to just a number is an example of formatting. 
- Calculating the order-to-receive interval is an example of transformation (often called feature engineering). 

In email, I have provided you our minimally processed CBC data both as a comma-separated value file (.csv) and as a weka-specific format (.arff). The .arff is ready to use directly in Weka, but you will not get the best classifier without some more pre-processing of the .csv. 

Data that has not been carefully pre-processed will produce meaningless results, even if the machine learning program completes without errors. This is the GIGO principle- [[https://en.wikipedia.org/wiki/Garbage_in,_garbage_out][garbage in, garbage out]]. 

** _OBJECTIVE: Your job is to use the available CBC data to predict which patients will become anemic._
In machine learning, this is an example of a supervised learning classifier problem. We will present the computer with examples of our two outcomes (subsequently anemic versus subsequently not anemic) and ask the computer to learn rules or patterns in the data that correlate with each group.  

Note: These results were selected so that the subs-anemia groups have comparable distributions of hemoglobin and hematocrit (see distributions above, for method see cbc-preprocess.R).

** Supervised Machine Learning Classifier
*** Import Data

Weka uses a specialized file format, .arff, which is just a .csv file with some extra header material. Weka can convert .csv files to .arff in the ARFF Viewer tool. 

- Open Weka, you will see the Wek GUI Chooser window
- Under the Tools menu at the top, choose ArffViewer: 

[[./tutorial-images/weka-open.png]]


- 


[[https://www.cs.waikato.ac.nz/ml/weka/downloading.html][Download]] a stable version of Weka for your operating system, and follow the installation instructions from the website. To import the CBC data that you have pre-processed, save that data as a comma-separated value (.csv) file. You can save as csv in Excel. Be sure the top of the spreadsheet contains only a single row of column labels, then only data beneath (see LINKexample). 

Now in the initial Weka window (Weka GUI Chooser), select ArffViewer the Tools menu. Open your csv in the ArffViewer. In the ArffViewer, you can modify the rows and columns of your data by right-clicking on them. The only important change to make is to identify an attribute as class- the column which describes the outcome you are trying to predict. Our classification attribute is subs-anemia. Right-click the column header for subs-anemia and select Attribute as Class. Now save as an .arff file type. 

*** Begin Classifying the Dataset

Back at the initial Weka GUI Chooser window, select the Weka Explorer program and open the .arff file you just created. 

- [ ] Preprocess tools

Select the Classify tab. Notice the setting for Classifier (ZeroR) and Cross-validation Folds (10). Recall the concept of cross-validation from Dr. Jackups machine learning lecture. Press start and look in the Classifier output window. Under  == Summary ==, you see about 1/2 of CBCs are correctly classified as preceding anemia or not (from the subs-anemia column) using the ZeroR algorithm. This is because ZeroR just picks the most prevalent category and assigns every instance to that category. This is your baseline, worst possible classifier.

You objective is to improve this classifier to get the highest possible correct classification using 10-fold cross validation. You will need to draw on strategies from the machine learning and data pre-processing lectures. These strategies include: 

- Optimize your dataset
  - Unless you direct Weka otherwise, it will use all the variables and all of the CBC values in your dataset, as is, for classification. You may improve your classification by changing the input data- using less variables, normalizing variables, re-scaling variables, or excluding incomplete values. 
- Select a better classification algorithm
  - The Choose button under the Classifier heading will direct you to a wide selection of classifier methods. 
  - [ ] Some common methods for this type of exercise include...
- Optimize your classifier algorithm
  - Each classifier algorithm has a set of pre-selected input parameters which are probably not optimized for this dataset. Select the text window to the right of the Choose button to change these parameters, then re-run to see if your classification gets better. 
  - [ ] These are explained in LINK

** Competition 

Iterate through the above process as much as you like to improve your classification. 

- [ ] Include resources

** Resources and References
- Weka Documentation
  - [[https://waikato.github.io/weka-wiki/search.html?q=time][wiki]]
